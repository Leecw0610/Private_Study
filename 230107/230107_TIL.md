# 230107 공부한 내용

---

- (인프런) 파이썬으로 배우는 알고리즘 기초 3강+4강 /28

  3. 알고리즘의 분석과 차수
  4. 분할정복

- (생활코딩) WEB2 Domain Name System 10~14강 (完)

- (생활코딩) VScode 기본 사용법 (完)

- (NeoWizard) 18강 RNN개념과 동작원리 ~ 23강 GRU기반의 삼성전자 주가 예측

- (인프런) Do it! 딥러닝 입문 01~05강

---

### 찾아본 내용

- [DL] RNN, LSTM 에서 tanh 를 사용하는 이유

```
RNN은 CNN과 달리 이전 step의 값을 가져와서 사용하므로 ReLU를 쓰게되면 이전 값이 커짐에 따라 전체적인 출력이 발산하는 문제가 생길 수 있다.
따라서 과거의 값들을 재귀적으로 사용하는 RNN 모델에서는 이를 normalizing 하는 것이 필요하며 이를 위해 sigmoid보다 기울기의 역전파가 더 잘되는 tanh를 사용함으로써 좋은 결과를 볼 수 있다고 한다.
즉, 과거의 값들이 끊임없이 재귀(반복적으로)로 사용되기때문에, -1~1 사이로 normalizing이 필요합니다.
```

- [DL] 시계열 데이터에 sin과 cos을 이용하는 이유

```
; 시계열 데이터를 분석하는 과정에서 주기적 성질(=계절성, Seasonality)을 지니고 있는 데이터들을 빈번히 발견할 수 있습니다.
데이터가 주기적 성질을 지니고 있다면 사인함수, 코사인함수와 같은 삼각함수의 합으로 표현이 가능합니다.


이 세상의 모든 복잡한 움직임 또는 운동이 주기적이란 성질을 갖고 있다면, 그것을 삼각함수(사인함수, 코사인 함수)로 이루어진 급수로 표현할 수 있다는 사실을 1822년 프랑스의 수학자 푸리에(Fourier, J.B.J. 1768~1830)가 발견했습니다.
삼각함수란 각에 대한 함수로서 삼각형의 각과 변의 길이를 연관시킨 것입니다. 그래서 우린 푸리에가 증명한 사실을 활용하여 복잡한 요소를 간단한 요소로 분해하고 그것을 재구성할 수 있습니다.
```

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbaWo4o%2FbtrseRikxJm%2F9eJ6qIvtiPQ11XxKkOkqI1%2Fimg.png)

- [DL] 장기 의존성 문제

```
  ; 입력 데이터가 많아질수록 simpleRNN 레이어에 보관하는 과거의 정보가 마지막 layer까지 충분히 전달되지 못하는 현상.
```

-[DL] pointwise operation

-[DL] 평균절대오차(MAE) 개념 및 특징

; 모든 절대 오차(Error)의 평균. MAE가 작을수록 알고리즘의 성능이 좋다

```
- MAE는 Outlier가 있어도 최대한 잘 추정된 데이터들의 특성을 반영할 수 있기 때문에 통계적으로 중앙값(Median)과 연관이 깊습니다.
반면 MSE의 경우, 에러 값이 증가함에 따라 손실 함수가 제곱배 만큼 커지기 때문에, Outlier의 오차를 줄이면 얻을 수 있는 Loss 이득이 훨씬 큽니다.
즉, MSE는 Outlier에 민감하다는 특징이 있습니다.

- MAE는 회귀(Regression) 문제에 자주 활용
```

[DL] 최적화기법 ; Momentum, AdaGrad, RMSProp, Adam

[DL] L1 , L2 규제 ; [Lasso, Ridge](https://rk1993.tistory.com/entry/Ridge-regression%EC%99%80-Lasso-regression-%EC%89%BD%EA%B2%8C-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0)

---

### 내일 할 일 ;

- (인프런) 파이썬으로 배우는 기초 알고리즘 5-6강

- (NeoWizard) 24~28강

- (인프런) Do it! 딥러닝 입문 06~09강

- (Kim Sung) 모두를 위한 딥러닝 시즌1 RNN 한번더 듣기!

- (Do it) 자연어 처리 교재 속독
