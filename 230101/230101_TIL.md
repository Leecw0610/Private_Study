# 230101 공부한 내용

---

### 프로그래머스 1단계 알고리즘 181 ~ 183

### 모두를 위한 딥러닝 강좌 시즌1 유튜브 영상 (kim sung)

4강 Multi-variable linear regression ~ 14강 (完)

---

### 찾아본 내용

- [python] 리스트 컴프리핸션에서 if문 사용하기

- [Python] deque 기본 설정( deque(iterable, maxlen) )

- [python] zip 함수, 별표(\*) ; unpack의 의미. list나 튜플을 풀어줌. 별표가 두개면 dict형태도 unpack

- [ML] sigmoid 함수

- [ML] one-hot encoding

- [python - numpy] flatten() 함수 ; 다차원 배열공간을 1차원으로 평탄화해줌

- [ML] 표준화 (Standardization); 표준정규분포의 속성을 갖도록 피처가 재조정
  vs 정규화 (Normalization); 데이터셋의 numerical value 범위의 차이를 왜곡하지 않고 공통 척도로 변경하는 것

```
Q. 그렇다면 정규화와 표준화의 차이는 무엇일까?

- 정규화(Normalization)

* 값의 범위(scale)을 0 ~ 1사이의 값으로 바꿔주는 것.
* 학습 전에 scaling하는 것

- 머신러닝에서 scale이 큰 feature의 영향이 비대해지는 것을 방지
- 딥러닝에서 Local Minima에 빠질 위험 감소(학습 속도 향상)

* scikit-learn에서 MinMaxScaler사용

- 표준화(Standardization)

* 값의 범위(scale)를 평균 0, 분산 1이 되도록 바꿔주는 것.
* 학습 전에 scaling하는 것

- 머신러닝에서 scale이 큰 feature의 영향이 비대해지는 것을 방지
- 딥러닝에서 Local Minima에 빠질 위험 감소(학습 속도 향상)

* 정규분포를 표준정규분포로 변환하는 것과 같음
* scikit-learn에서 StandardScaler
```

- [DL] Epoch, Iteration, Batch size 개념

- [DL] shape, rank, axis

- [DL] Vanishing gradient

- [DL] Restricted Boatman Machine (RBM)

---

### 내일 할 일 ;

- 알고리즘 2단계 풀기 (아침)

- 자연어, 이미지 처리 예습 (wikidocs 자연어처리)

- Do it! 자연어 처리 교재

- ML & DL 우선순위 하나씩

  1. W3school (machine learning part),

  2. wikidocs pytorch로 시작하는 딥러닝 입문

  3. wikidocs 한땀한땀 딥러닝 컴퓨터 비전 백과사전
